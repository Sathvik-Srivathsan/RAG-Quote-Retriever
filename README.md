# RAG-Quote-Retriever
# Semantic Quote Retriever with RAG

This project is a Streamlit web application that allows users to search for quotes based on their semantic meaning (not just keywords). It uses a Retrieval Augmented Generation (RAG) pipeline:

1. **Retrieval:** Finds relevant quotes using sentence embeddings and a FAISS vector index.
2. **Generation:** Uses a Large Language Model (LLM) to generate a summary or answer based on the retrieved quotes and the user's query.

## Features

- Loads quotes from a Hugging Face dataset (`Abirate/english_quotes`).
- Cleans and preprocesses text data.
- Generates sentence embeddings using `all-MiniLM-L6-v2`.
- Builds a FAISS index for efficient similarity search.
- Retrieves top-k relevant quotes for a user query.
- Uses `google/flan-t5-small` to generate a contextual response.
- Interactive web interface built with Streamlit.
- Caches processed data, embeddings, index, and models for faster subsequent runs.

## How it Works (Simplified for Beginners)

Imagine you have a huge library of quotes.

1. **Understanding Quotes:** We first teach a computer to understand the *meaning* of each quote. It does this by converting each quote into a special list of numbers (called an "embedding"). Quotes with similar meanings will have similar lists of numbers.
2. **Indexing for Speed:** To quickly find similar quotes later, we put all these number-lists into a special, super-fast address book (this is the "FAISS index").
3. **Your Query:** When you ask a question (your "query"), we also convert your question into a similar list of numbers.
4. **Finding Matches (Retrieval):** We use the FAISS address book to find the quotes whose number-lists are most similar to your question's number-list. These are the "retrieved quotes."
5. **Smart Answers (Generation):** We then take your original question and the most relevant quotes we found, and give them to a very smart "Language Model" (like a super-powered chatbot). This model reads everything and writes a nice answer or summary for you. This is "Retrieval Augmented Generation" â€“ we *retrieve* information to *augment* (help) the *generation* of an answer.

## Prerequisites

Python 3.8+

## Setup and Installation

**Install Required Libraries:**
```
pip install streamlit pandas numpy faiss-cpu datasets sentence-transformers transformers torch

```

## Running the Application

**2. Run the Streamlit app:**
```
streamlit run rag_quote_app.py

```

(If you named your file something else, replace `rag_quote_app.py` with that filename).

**3. Open in Browser:**
Streamlit will usually automatically open a new tab in your web browser pointing to the application (e.g., `http://localhost:8501`). 
If not, the terminal will display the URL you can copy and paste into your browser.

## Using the Application

1. **Query Input:** Type your question or topic about quotes into the text box labeled "Enter your query about quotes:".
2. **Number of Quotes:** Use the slider to select how many relevant quotes should be retrieved and used as context for the LLM.
3. **Search:** Click the "Search for Quotes" button.
4. **Results:**
    - **LLM Generated Summary/Answer:** The app will display a response generated by the LLM based on your query and the retrieved quotes.
    - **Retrieved Quotes:** Below the summary, you'll see the actual quotes that were found to be most relevant, along with their authors and similarity scores. These are expandable.
    - **JSON Output:** A structured JSON output of the query, summary, and retrieved entries is also provided for programmatic use or inspection.
5. **Example Queries:** The sidebar has some example queries you can click to auto-fill the input box.


What the StreamLit WebApp look like example:
![image](https://github.com/user-attachments/assets/1ed864f0-ba7f-40d5-af32-710a4d2083fd)
![image](https://github.com/user-attachments/assets/13b08739-0687-4f2f-9967-54a9b5d6f1e3)
